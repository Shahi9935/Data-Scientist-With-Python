{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatinating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 5)\n",
      "(97, 5)\n",
      "(297, 5)\n",
      "   Unnamed: 0         Date/Time      Lat      Lon    Base\n",
      "0           0  4/1/2014 0:11:00  40.7690 -73.9549  B02512\n",
      "1           1  4/1/2014 0:17:00  40.7267 -74.0345  B02512\n",
      "2           2  4/1/2014 0:21:00  40.7316 -73.9873  B02512\n",
      "3           3  4/1/2014 0:28:00  40.7588 -73.9776  B02512\n",
      "4           4  4/1/2014 0:33:00  40.7594 -73.9722  B02512\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "uber=pd.read_csv('nyc_uber_2014.csv')\n",
    "uber1=uber.loc[0:99,:] #(loc takes position from x to y ,unlike without using loc,which takes x to y-1 )\n",
    "uber2=uber[100:200]\n",
    "uber3=uber[200:]\n",
    "print(uber1.shape)\n",
    "print(uber2.shape)\n",
    "print(uber3.shape)\n",
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1,uber2,uber3])\n",
    "\n",
    "# Print the shape of row_concat\n",
    "print(row_concat.shape)\n",
    "\n",
    "# Print the head of row_concat\n",
    "print(row_concat.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining columns of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column-wise concatenation of data is same as stitching data together from the sides instead of the top and bottom. To perform this action,we use the same pd.concat() function, but this time with the keyword argument axis=1. The default, axis=0, is for a row-wise concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        type country\n",
      "0      Cases  Guinea\n",
      "1      Cases  Guinea\n",
      "2      Cases  Guinea\n",
      "3      Cases  Guinea\n",
      "4      Cases  Guinea\n",
      "5      Cases  Guinea\n",
      "6      Cases  Guinea\n",
      "7      Cases  Guinea\n",
      "8      Cases  Guinea\n",
      "9      Cases  Guinea\n",
      "10     Cases  Guinea\n",
      "11     Cases  Guinea\n",
      "12     Cases  Guinea\n",
      "13     Cases  Guinea\n",
      "14     Cases  Guinea\n",
      "15     Cases  Guinea\n",
      "16     Cases  Guinea\n",
      "17     Cases  Guinea\n",
      "18     Cases  Guinea\n",
      "19     Cases  Guinea\n",
      "20     Cases  Guinea\n",
      "21     Cases  Guinea\n",
      "22     Cases  Guinea\n",
      "23     Cases  Guinea\n",
      "24     Cases  Guinea\n",
      "25     Cases  Guinea\n",
      "26     Cases  Guinea\n",
      "27     Cases  Guinea\n",
      "28     Cases  Guinea\n",
      "29     Cases  Guinea\n",
      "...      ...     ...\n",
      "1922  Deaths    Mali\n",
      "1923  Deaths    Mali\n",
      "1924  Deaths    Mali\n",
      "1925  Deaths    Mali\n",
      "1926  Deaths    Mali\n",
      "1927  Deaths    Mali\n",
      "1928  Deaths    Mali\n",
      "1929  Deaths    Mali\n",
      "1930  Deaths    Mali\n",
      "1931  Deaths    Mali\n",
      "1932  Deaths    Mali\n",
      "1933  Deaths    Mali\n",
      "1934  Deaths    Mali\n",
      "1935  Deaths    Mali\n",
      "1936  Deaths    Mali\n",
      "1937  Deaths    Mali\n",
      "1938  Deaths    Mali\n",
      "1939  Deaths    Mali\n",
      "1940  Deaths    Mali\n",
      "1941  Deaths    Mali\n",
      "1942  Deaths    Mali\n",
      "1943  Deaths    Mali\n",
      "1944  Deaths    Mali\n",
      "1945  Deaths    Mali\n",
      "1946  Deaths    Mali\n",
      "1947  Deaths    Mali\n",
      "1948  Deaths    Mali\n",
      "1949  Deaths    Mali\n",
      "1950  Deaths    Mali\n",
      "1951  Deaths    Mali\n",
      "\n",
      "[1952 rows x 2 columns]\n",
      "(1952, 6)\n",
      "         Date  Day  type_country  counts   type country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "ebola=pd.read_csv('ebola.csv')\n",
    "ebola_melt = pd.melt(ebola, id_vars=['Date','Day'], var_name='type_country', value_name='counts')\n",
    "status_country=pd.DataFrame()\n",
    "extra=pd.DataFrame()\n",
    "# Create the 'str_split' column\n",
    "extra['str_split'] =ebola_melt['type_country'].str.split('_')\n",
    "\n",
    "# Create the 'type' column\n",
    "status_country['type'] = extra['str_split'].str.get(0)\n",
    "\n",
    "# Create the 'country' column\n",
    "status_country['country'] = extra['str_split'].str.get(1)\n",
    "\n",
    "\n",
    "# Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "ebola_tidy = pd.concat([ebola_melt,status_country],axis=1)\n",
    "\n",
    "# Print the shape of ebola_tidy\n",
    "print(ebola_tidy.shape)\n",
    "\n",
    "# Print the head of ebola_tidy\n",
    "print(ebola_tidy.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pattern Matching in Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glob module is used to find all csv files in the workspace which has a function called glob that takes a pattern and returns a list of the files in the working directory that match that pattern.\n",
    "\n",
    "For example, if we  know the pattern is part_ single digit number .csv, we can write the pattern as 'part_?.csv' (which would match part_1.csv, part_2.csv, part_3.csv, etc.)\n",
    "\n",
    "Similarly, we can find all .csv files with '*.csv', or all parts with 'part_*'. \n",
    "\n",
    "The ? wildcard represents any 1 character, and the * wildcard represents any number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airquality.csv', 'dob_job_application_filings_subset.csv', 'ebola.csv', 'gapminder.csv', 'nyc_uber_2014.csv', 'tb.csv', 'tips.csv']\n",
      "       Job #  Doc #        Borough       House #  \\\n",
      "0  121577873      2      MANHATTAN  386            \n",
      "1  520129502      1  STATEN ISLAND  107            \n",
      "2  121601560      1      MANHATTAN  63             \n",
      "3  121601203      1      MANHATTAN  48             \n",
      "4  121601338      1      MANHATTAN  45             \n",
      "\n",
      "                        Street Name  Block  Lot    Bin # Job Type Job Status  \\\n",
      "0  PARK AVENUE SOUTH                   857   38  1016890       A2          D   \n",
      "1  KNOX PLACE                          342    1  5161350       A3          A   \n",
      "2  WEST 131 STREET                    1729    9  1053831       A2          Q   \n",
      "3  WEST 25TH STREET                    826   69  1015610       A2          D   \n",
      "4  WEST 29 STREET                      831    7  1015754       A3          D   \n",
      "\n",
      "            ...                         Owner's Last Name  \\\n",
      "0           ...            MIGLIORE                         \n",
      "1           ...            BLUMENBERG                       \n",
      "2           ...            MARKOWITZ                        \n",
      "3           ...            CASALE                           \n",
      "4           ...            LEE                              \n",
      "\n",
      "              Owner's Business Name Owner's House Number  \\\n",
      "0  MACKLOWE MANAGEMENT                      126            \n",
      "1  NA                                       107            \n",
      "2  635 RIVERSIDE DRIVE NY LLC               619            \n",
      "3  48 W 25 ST LLC C/O BERNSTEIN             150            \n",
      "4  HYUNG-HYANG REALTY CORP                  614            \n",
      "\n",
      "           Owner'sHouse Street Name            City  State    Zip  \\\n",
      "0  EAST 56TH STREET                  NEW YORK           NY  10222   \n",
      "1  KNOX PLACE                        STATEN ISLAND      NY  10314   \n",
      "2  WEST 54TH STREET                  NEW YORK           NY  10016   \n",
      "3  WEST 30TH STREET                  NEW YORK           NY  10001   \n",
      "4  8 AVENUE                          NEW YORK           NY  10001   \n",
      "\n",
      "  Owner'sPhone #                                    Job Description  \\\n",
      "0     2125545837  GENERAL MECHANICAL & PLUMBING MODIFICATIONS AS...   \n",
      "1     3477398892  BUILDERS PAVEMENT PLAN 143 LF.                ...   \n",
      "2     2127652555  GENERAL CONSTRUCTION TO INCLUDE NEW PARTITIONS...   \n",
      "3     2125941414  STRUCTURAL CHANGES ON THE 5TH FLOOR (MOONDOG E...   \n",
      "4     2019881222  FILING HEREWITH FACADE REPAIR PLANS. WORK SCOP...   \n",
      "\n",
      "               DOBRunDate  \n",
      "0  04/26/2013 12:00:00 AM  \n",
      "1  04/26/2013 12:00:00 AM  \n",
      "2  04/26/2013 12:00:00 AM  \n",
      "3  04/26/2013 12:00:00 AM  \n",
      "4  04/26/2013 12:00:00 AM  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern ='*.csv'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Print the file names\n",
    "print(csv_files)\n",
    "\n",
    "# Load the second file into a DataFrame: csv2\n",
    "csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# Print the head of csv2\n",
    "print(csv2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14643, 353)\n",
      "   1800  1801  1802  1803  1804  1805  1806  1807  1808  1809  ...   m5564  \\\n",
      "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...     NaN   \n",
      "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...     NaN   \n",
      "2   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...     NaN   \n",
      "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...     NaN   \n",
      "4   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...     NaN   \n",
      "\n",
      "   m65  mu  sex  size  smoker  time  tip  total_bill  year  \n",
      "0  NaN NaN  NaN   NaN     NaN   NaN  NaN         NaN   NaN  \n",
      "1  NaN NaN  NaN   NaN     NaN   NaN  NaN         NaN   NaN  \n",
      "2  NaN NaN  NaN   NaN     NaN   NaN  NaN         NaN   NaN  \n",
      "3  NaN NaN  NaN   NaN     NaN   NaN  NaN         NaN   NaN  \n",
      "4  NaN NaN  NaN   NaN     NaN   NaN  NaN         NaN   NaN  \n",
      "\n",
      "[5 rows x 353 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list: frames\n",
    "frames = []\n",
    "\n",
    "#  Iterate over csv_files\n",
    "for csv in csv_files:\n",
    "\n",
    "    #  Read csv into a DataFrame: df\n",
    "    df =pd.read_csv(csv)\n",
    "    \n",
    "    # Append df to frames\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate frames into a single DataFrame: uber\n",
    "uber = pd.concat(frames)\n",
    "\n",
    "# Print the shape of uber\n",
    "print(uber.shape)\n",
    "\n",
    "# Print the head of uber\n",
    "print(uber.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now programmatically combine datasets that are broken up into many smaller parts. We'll find many datasets in the wild will be stored this way, particularly data that is collected incrementally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging data allows us to combine disparate datasets into a single dataset to do more complex analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'site' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fa1a7a84db0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Merge the DataFrames: o2o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mo2o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvisited\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'site'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print o2o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo2o\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'site' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print o2o\n",
    "print(o2o)\n",
    "print(site.shape)\n",
    "print('\\n\\n\\n')\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many to Many\n",
    "The final merging scenario occurs when both DataFrames do not have unique keys for a merge. What happens here is that for each duplicated key, every pairwise combination will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
